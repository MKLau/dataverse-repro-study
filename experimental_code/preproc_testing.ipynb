{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_lines = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = '\\\"mydir/mystuff/myfile.csv\\\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_match = re.match(\"(?:\\\"([^\\\"]*)\\\")|(?:\\'([^\\']*)\\')\", test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(my_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_group1 = my_match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = match_group1.split(\"\\\\\")[-1]\n",
    "file_name = file_name.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = re.match(\".*?\\s*(\\S+\\.[^ \\s,]+)\\s*\", file_name).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myfile.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def doi_to_directory(doi):\n",
    "\t\"\"\"Converts a doi string to a more directory-friendly name\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdoi : string\n",
    "\t\t  doi\n",
    "\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdoi : string\n",
    "\t\t  doi with \"/\" and \":\" replaced by \"-\" and \"--\" respectively\n",
    "\t\"\"\"\n",
    "\treturn doi.replace(\"/\", \"-\").replace(\":\", \"--\")\n",
    "\n",
    "def directory_to_doi(doi):\n",
    "\t\"\"\"Converts a doi string to a more directory-friendly name\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdoi : string\n",
    "\t\t  doi\n",
    "\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdoi : string\n",
    "\t\t  doi with \"-\" and \"--\" replaced by \"/\" and \":\" respectively\n",
    "\t\"\"\"\n",
    "\treturn doi.replace(\"--\", \":\").replace(\"-\", \"/\")\n",
    "\n",
    "def get_r_dois(dataverse_key, save=False, print_status=False,\n",
    "\t\t\t   api_url=\"https://dataverse.harvard.edu/api/search/\"):\n",
    "\t\"\"\"Get list of dois for all R files in a dataverse (defaulting to Harvard's)\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdataverse_key : string \n",
    "\t\t\t\t\tcontaining user's dataverse API key\n",
    "\tsave : boolean\n",
    "\t\t   whether or not to save the result as a .txt file\n",
    "\tprint_status : boolean\n",
    "\t\t\t\t   whether or not to print status messages\n",
    "\tapi_url : string\n",
    "\t\t\t  url pointing to the dataverse to get URLs for\n",
    "\tReturns\n",
    "\t-------\n",
    "\tr_dois : list of string\n",
    "\t\t\t dois containing r_files in Harvard dataverse\n",
    "\t\"\"\"\n",
    "\t# defining some constants\n",
    "\tr_file_query = \"fileContentType:type/x-r-syntax\"\n",
    "\n",
    "\t# initialize variables to store current state of scraping\n",
    "\tpage_num = 0\n",
    "\tr_dois = []\n",
    "\n",
    "\t#  keep requesting until the API returns fewer than 1000 results\n",
    "\twhile True:\n",
    "\t\tif print_status:\n",
    "\t\t\tprint(\"Requesting page {} from API...\".format(page_num))\n",
    "\t\t# query the API for 1000 results\n",
    "\t\tmyresults = requests.get(api_url,\n",
    "\t\t\t\t\t\t\t\t params= {\"q\": r_file_query, \"type\": \"file\",\n",
    "\t\t\t\t\t\t\t\t \"key\": dataverse_key,\n",
    "\t\t\t\t\t\t\t\t \"start\": str(1000 * page_num),\n",
    "\t\t\t\t\t\t\t\t \"per_page\": str(1000)}).json()['data']['items']\n",
    "\n",
    "\t\tif print_status:\n",
    "\t\t\tprint(\"Parsing results from page {}...\".format(page_num))\n",
    "\t\t\n",
    "\t\t# iterate through results, recording dataset_citations\n",
    "\t\tfor myresult in myresults:\n",
    "\t\t\t# extract the DOI (if any) from the result\n",
    "\t\t\tdoi_match = re.search(\"(doi:[^,]*)\", myresult['dataset_citation'])\n",
    "\t\t\tif doi_match:\n",
    "\t\t\t\tr_dois.append(doi_match.group(1) + '\\n')\n",
    "\n",
    "\t\t# if fewer than 1000 results were returned; we must have reached the end\n",
    "\t\tif len(myresults) < 1000:\n",
    "\t\t\tif print_status:\n",
    "\t\t\t\tprint(\"Reached last page of results. Done.\")\n",
    "\t\t\tbreak\n",
    "\t\tpage_num += 1\n",
    "\n",
    "\t# remove duplicate DOIs\n",
    "\tr_dois = list(set(r_dois))\n",
    "\n",
    "\t# if save, then save as .txt file \n",
    "\tif save:\n",
    "\t\t# remove old output file if one exists\n",
    "\t\tif os.path.exists('r_dois.txt'):   \n",
    "\t\t\tos.remove('r_dois.txt')\n",
    "\n",
    "\t\t# write dois to file, one-per-line\n",
    "\t\twith open('r_dois.txt', 'a') as myfile:\n",
    "\t\t\tmap(myfile.write, r_dois)\n",
    "\treturn r_dois\n",
    "\n",
    "def get_runlog_data(path_to_datasets):\n",
    "\t\"\"\"Aggregate run-time data for all datasets in the given\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpath_to_datasets : string \n",
    "\t\t\t\t\t   path to the directory containing processed datasets\n",
    "\tReturns\n",
    "\t-------\n",
    "\t(run_data_df, error_dois) : tuple of (pandas.DataFrame, list of string)\n",
    "\t\t\t\t\t\t\t\ta tuple containing a pandas DataFrame with the \n",
    "\t\t\t\t\t\t\t\taggregated results of attempting to run the R code\n",
    "\t\t\t\t\t\t\t\tin all the datasets, followed by a list of datasets\n",
    "\t\t\t\t\t\t\t\tfor which aggregating the results failed (should be\n",
    "\t\t\t\t\t\t\t\tan empty list unless there was a catastrophic error)\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t# get list of dataset directories, ignoring macOS directory metadata file (if present)\n",
    "\tdoi_directs = [doi for doi in os.listdir(path_to_datasets) if doi != '.DS_Store']\n",
    "\t# initialize empty dataframe to store run logs of all the files\n",
    "\trun_data_df = pd.DataFrame()\n",
    "\t# initialize empty list to store problem doi's\n",
    "\terror_dois = []\n",
    "\n",
    "\t# iterate through directories and concatenate run logs\n",
    "\tfor my_doi in doi_directs:\n",
    "\t\ttry:\n",
    "\t\t\t# assemble path\n",
    "\t\t\tmy_path = path_to_datasets + '/' + my_doi + '/prov_data/' + 'run_log.csv'\n",
    "\t\t\t# concatenate to dataframe\n",
    "\t\t\trun_data_df = pd.concat([run_data_df, pd.read_csv(my_path)])\n",
    "\t\texcept:\n",
    "\t\t\terror_dois.append(my_doi)\n",
    "\treturn (run_data_df, error_dois)\n",
    "\n",
    "def refresh_datasets(path_to_datasets):\n",
    "\t\"\"\"Clean datasets of all traces of preprocessing and provenance collection\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpath_to_datasets : string \n",
    "\t\t\t\t\t   path to the directory containing processed datasets\n",
    "\t\"\"\"\n",
    "\t# get list of dataset directories, ignoring macOS directory metadata file (if present)\n",
    "\tdoi_directs = [doi for doi in os.listdir(path_to_datasets) if doi != '.DS_Store']\n",
    "\n",
    "\t# iterate through directories, deleting prov_data directory and preprocessed files\n",
    "\tfor my_doi in doi_directs:\n",
    "\t\t# assemble paths\n",
    "\t\tdoi_dir_path = path_to_datasets + '/' + my_doi\n",
    "\t\t# get list of ignoring macOS directory metadata file (if present)\n",
    "\t\tdoi_files = [my_file for my_file in os.listdir(doi_dir_path) if\\\n",
    "\t\t\t\t\t my_file != '.DS_Store' and re.match('.*__preproc__', my_file)]\n",
    "\t\t# remove preprocessed files\n",
    "\t\tfor my_file in doi_files:\n",
    "\t\t\tdoi_file_path = doi_dir_path + '/' + my_file\n",
    "\t\t\ttry: \n",
    "\t\t\t\tos.remove(doi_file_path)\n",
    "\t\t\texcept OSError:\n",
    "\t\t\t\tpass\n",
    "\t\t# remove prov_data directory\n",
    "\t\ttry:\n",
    "\t\t\tshutil.rmtree(doi_dir_path + '/prov_data')\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "def find_file(pattern, path):\n",
    "\t\"\"\"Recursively search the directory pointed to by path for a file matching pattern.\n",
    "\t   Inspired by https://stackoverflow.com/questions/120656/directory-listing-in-python\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpattern : string\n",
    "\t\t\t  unix-style pattern to attempt to match to a file\n",
    "\tpath : string\n",
    "\t\t   path to the directory to search\n",
    "\n",
    "\tReturns \n",
    "\t-------\n",
    "\tstring \n",
    "\tpath to a matching file or the empty string\n",
    "\t\"\"\"\n",
    "\tfor root, dirs, files in os.walk(path):\n",
    "\t\tfor name in files:\n",
    "\t\t\tif fnmatch.fnmatch(name, pattern):\n",
    "\t\t\t\treturn '/'.join((os.path.join(root, name)).split('/')[1:])\n",
    "\treturn ''\n",
    "\n",
    "def find_dir(pattern, path):\n",
    "\t\"\"\"Recursively search the directory pointed to by path for a directory matching pattern.\n",
    "\t   Inspired by https://stackoverflow.com/questions/120656/directory-listing-in-python\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpattern : string\n",
    "\t\t\t  unix-style pattern to attempt to match to a directory\n",
    "\tpath : string\n",
    "\t\t   path to the directory to search\n",
    "\n",
    "\tReturns \n",
    "\t-------\n",
    "\tstring \n",
    "\tpath to a matching directory or the empty string\n",
    "\t\"\"\"\n",
    "\tfor root, dirs, files in os.walk(path):\n",
    "\t\tfor name in dirs:\n",
    "\t\t\tif fnmatch.fnmatch(name, pattern):\n",
    "\t\t\t\treturn '/'.join((os.path.join(root, name)).split('/')[1:])\n",
    "\treturn ''\n",
    "\n",
    "def preprocess_lib(r_file, path, from_preproc=False):\n",
    "\t\"\"\"Replace calls to \"library\", \"require\", and \"install.packages\" with a special function,\n",
    "\t   \"install_and_load\". Please see install_and_load.R for more details. \n",
    "\tParameters\n",
    "\t----------\n",
    "\tr_file: string\n",
    "\t\t\tname of the R file to be preprocessed\n",
    "\tfile_path : string\n",
    "\t\t\t\tpath to the directory containing the R file\n",
    "\tfrom_preproc : boolean\n",
    "\t\t\t\t   whether the r_file has already been preprocessed\n",
    "\n",
    "\t\"\"\"\n",
    "\t# parse out filename and construct file path\n",
    "\tfilename = r_file.split(\".R\")[0]\n",
    "\tfile_path = path + \"/\" + r_file\n",
    "\t# path to preprocessed file, named with suffix \"__preproc__\"\n",
    "\tpreproc_path = path + \"/\" + filename + \"__preproc__\" + \".R\"\n",
    "\t# path to temp file, named with suffix \"_temp\"\n",
    "\tfile_to_copy = path + \"/\" + filename + \"_temp\" + \".R\"\n",
    "\t# if file has already been preprocessed, rename the preprocessed file\n",
    "\t# to a temporary file with _temp suffix, freeing up the __preproc__ suffix to be used \n",
    "\t# for the file generated by this function\n",
    "\tif from_preproc:\n",
    "\t\tos.rename(preproc_path, file_to_copy)\n",
    "\telse:\n",
    "\t\tfile_to_copy = file_path\n",
    "\n",
    "\t# wipe the preprocessed file and open it for writing\n",
    "\twith open(preproc_path, 'w') as outfile:\n",
    "\t\t# add in declaration for \"install_and_load\" at the head of the preprocessed file\n",
    "\t\twith open(\"install_and_load.R\", 'r') as infile:\n",
    "\t\t\tmap(outfile.write, infile.readlines())\n",
    "\t\t\toutfile.write(\"\\n\")\n",
    "\t\t# write code from .R file, replacing function calls as necessary\n",
    "\t\twith open(file_to_copy, 'r') as infile:\n",
    "\t\t\tfor line in infile.readlines():\n",
    "\t\t\t\t# ignore commented lines\n",
    "\t\t\t\tif re.match(\"^#\", line):\n",
    "\t\t\t\t\toutfile.write(line)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# replace \"library\" calls\n",
    "\t\t\t\t\tlibrary_replace = re.sub(\"library\\s*\\(\\\"?([^\\\"]*)\\\"?\\)\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t \"install_and_load(\\\"\\\\1\\\")\", line)\n",
    "\t\t\t\t\t# replace \"require\" calls\n",
    "\t\t\t\t\trequire_replace = re.sub(\"require\\s*\\(\\\"?([^\\\"]*)\\\"?\\)\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t \"install_and_load(\\\"\\\\1\\\")\", library_replace)\n",
    "\t\t\t\t\t# replace \"install.packages\" calls\n",
    "\t\t\t\t\tinstall_replace = re.sub(\"install.packages\\s*\\(\\\"?([^\\\"]*)\\\"?\\)\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t \"install_and_load(\\\"\\\\1\\\")\", require_replace)\n",
    "\t\t\t\t\t# write the preprocessed result\n",
    "\t\t\t\t\toutfile.write(install_replace)\n",
    "\t\t\t\t\t# if the line clears the environment, re-declare \"install_and_load\" immediately after\n",
    "\t\t\t\t\tif re.match(\"^rm\\s*\\(\", line):\n",
    "\t\t\t\t\t\twith open(\"install_and_load.R\", 'r') as install_and_load:\n",
    "\t\t\t\t\t\t\tmap(outfile.write, install_and_load.readlines())\n",
    "\t\t\t\t\t\t\toutfile.write(\"\\n\")\n",
    "\t\n",
    "\t# remove the file with _temp suffix if file was previously preprocessed\n",
    "\tif from_preproc:\n",
    "\t\tos.remove(file_to_copy)\n",
    "\n",
    "def extract_directory(path):\n",
    "\t\"\"\"Parse out directory name from a file path\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpath : string\n",
    "\t\t   input path to parse filename from\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdir_name : string\n",
    "\t\t\t   file name (last part of path), \n",
    "\t\t\t   empty string if none found      \n",
    "\t\"\"\"\n",
    "\t# get last group of a path\n",
    "\treturn (path.split(\"\\\\\")[-1]).split(\"/\")[-1]\n",
    "\n",
    "def extract_filename(path):\n",
    "\t\"\"\"Parse out the file name from a file path\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpath : string\n",
    "\t\t   input path to parse filename from\n",
    "\tReturns\n",
    "\t-------\n",
    "\tfile_name : string\n",
    "\t\t\t\tfile name (last part of path), \n",
    "\t\t\t\tempty string if none found\n",
    "\t\"\"\"\n",
    "\t# get last group of a path\n",
    "\tif path:\n",
    "\t\tfile_name = extract_directory(path)\n",
    "\t\tfile_name = re.match(\".*?\\s*(\\S+\\.[^ \\s,]+)\\s*\", file_name)\n",
    "\t\tif file_name:\n",
    "\t\t\treturn file_name.group(1)\n",
    "\treturn ''\n",
    "\n",
    "def preprocess_setwd(r_file, path, from_preproc=False):\n",
    "\t\"\"\"Attempt to correct setwd errors by finding the correct directory or deleting the function call\n",
    "\tParameters\n",
    "\t----------\n",
    "\tr_file: string\n",
    "\t\t\tname of the R file to be preprocessed\n",
    "\tpath : string\n",
    "\t\t   path to the directory containing the R file\n",
    "\tfrom_preproc : boolean\n",
    "\t\t\t\t   whether the r_file has already been preprocessed (default False)\n",
    "\n",
    "\t\"\"\"\n",
    "\t# parse out filename and construct file path\n",
    "\tfilename = r_file.split(\".R\")[0]\n",
    "\tfile_path = path + \"/\" + r_file\n",
    "\t# path to preprocessed file, named with suffix \"_preproc\"\n",
    "\tpreproc_path = path + \"/\" + filename + \"__preproc__\" + \".R\"\n",
    "\t# path to temp file, named with suffix \"_temp\"\n",
    "\tfile_to_copy = path + \"/\" + filename + \"_temp\" + \".R\"\n",
    "\t# if file has already been preprocessed, rename the preprocessed file\n",
    "\t# to a temporary file with _temp suffix, freeing up the __preproc__ suffix to be used \n",
    "\t# for the file generated by this function\n",
    "\tif from_preproc:\n",
    "\t\tos.rename(preproc_path, file_to_copy)\n",
    "\telse:\n",
    "\t\tfile_to_copy = file_path\n",
    "\n",
    "\t# for storing return value\n",
    "\tpath_to_wd = ''\n",
    "\n",
    "\t# wipe the preprocessed file and open it for writing\n",
    "\twith open(preproc_path, 'w') as outfile:\n",
    "\t\t# write code from .R file, replacing function calls as necessary\n",
    "\t\twith open(file_to_copy, 'r') as infile:\n",
    "\t\t\tfor line in infile.readlines():\n",
    "\t\t\t\t# ignore commented lines\n",
    "\t\t\t\tif re.match(\"^#\", line):\n",
    "\t\t\t\t\toutfile.write(line)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcontains_setwd = re.match(\"setwd\\s*\\(\\\"?([^\\\"]*)\\\"?\\)\", line)\n",
    "\t\t\t\t\t# if the line contains a call to setwd\n",
    "\t\t\t\t\tif contains_setwd:\n",
    "\t\t\t\t\t\t# try to isolate only the directory portion of the intended path\n",
    "\t\t\t\t\t\twd_name = extract_directory(contains_setwd.group(1))\n",
    "\t\t\t\t\t\t# try to find the path to the working directory (if any)\n",
    "\t\t\t\t\t\tpath_to_wd = find_dir(wd_name, path)\n",
    "\t\t\t\t\t\t# if a path was found, append modified setwd call to file\n",
    "\t\t\t\t\t\tif path_to_wd:\n",
    "\t\t\t\t\t\t\toutfile.write(\"setwd(\" + \"\\\"\" + path_to_wd + \"\\\"\" + \")\")\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\toutfile.write(line)\n",
    "\t\n",
    "\t# remove the file with _temp suffix if file was previously preprocessed\n",
    "\tif from_preproc:\n",
    "\t\tos.remove(file_to_copy)\n",
    "\treturn path_to_wd\n",
    "\n",
    "def preprocess_file_paths(r_file, path, wd_path='', from_preproc=False):\n",
    "\t\"\"\"Attempt to correct setwd errors by finding the correct directory or deleting the function call\n",
    "\tParameters\n",
    "\t----------\n",
    "\tr_file: string\n",
    "\t\t\tname of the R file to be preprocessed\n",
    "\tpath : string\n",
    "\t\t   path to the directory containing the R file\n",
    "\twd_path : string\n",
    "\t\t\t  path to the working directory the R file references, (root directory for file searches)\n",
    "\tfrom_preproc : boolean\n",
    "\t\t\t\t   whether the r_file has already been preprocessed (default False)\n",
    "\t\"\"\"\n",
    "\t# parse out filename and construct file path\n",
    "\tfilename = r_file.split(\".R\")[0]\n",
    "\tfile_path = path + \"/\" + r_file\n",
    "\t# path to preprocessed file, named with suffix \"_preproc\"\n",
    "\tpreproc_path = path + \"/\" + filename + \"__preproc__\" + \".R\"\n",
    "\t# path to temp file, named with suffix \"_temp\"\n",
    "\tfile_to_copy = path + \"/\" + filename + \"_temp\" + \".R\"\n",
    "\t# if file has already been preprocessed, rename the preprocessed file\n",
    "\t# to a temporary file with _temp suffix, freeing up the __preproc__ suffix to be used \n",
    "\t# for the file generated by this function\n",
    "\tif from_preproc:\n",
    "\t\tos.rename(preproc_path, file_to_copy)\n",
    "\telse:\n",
    "\t\tfile_to_copy = file_path\n",
    "\t# wipe the preprocessed file and open it for writing\n",
    "\twith open(preproc_path, 'w') as outfile:\n",
    "\t\t# write code from .R file, replacing function calls as necessary\n",
    "\t\twith open(file_to_copy, 'r') as infile:\n",
    "\t\t\tfor line in infile.readlines():\n",
    "\t\t\t\t# ignore commented lines\n",
    "\t\t\t\tif re.match(\"^#\", line):\n",
    "\t\t\t\t\toutfile.write(line)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcontains_string = re.search(\"(?:\\\"([^\\\"]*)\\\")|(?:\\'([^\\']*)\\')\", line)\n",
    "\t\t\t\t\t# if the line contains a call to setwd\n",
    "\t\t\t\t\tif contains_string:\n",
    "\t\t\t\t\t\t# get the filename (if any)\n",
    "\t\t\t\t\t\tfile_name = extract_filename(contains_string.group(1))\n",
    "\t\t\t\t\t\t# try to isolate only the filename portion of the intended path\n",
    "\t\t\t\t\t\tif file_name:\n",
    "\t\t\t\t\t\t\t# try to find the path to the working directory (if any)\n",
    "\t\t\t\t\t\t\tpath_to_file = find_file(file_name, '/'.join(path, wd_path))\n",
    "\t\t\t\t\t\t\t# if a path was found, append modified setwd call to file\n",
    "\t\t\t\t\t\t\tif path_to_file:\n",
    "\t\t\t\t\t\t\t\tline = re.sub(contains_string.group(1), path_to_file, line)\n",
    "\t\t\t\t\toutfile.write(line)\n",
    "\t\n",
    "\t# remove the file with _temp suffix if file was previously preprocessed\n",
    "\tif from_preproc:\n",
    "\t\tos.remove(file_to_copy)\n",
    "\n",
    "def all_preproc(r_file, path, error_string=\"error\"):\n",
    "\t\"\"\"Attempt to correct setwd, file path, and library errors\n",
    "\tParameters\n",
    "\t----------\n",
    "\tr_file: string\n",
    "\t\t\tname of the R file to be preprocessed\n",
    "\tpath : string\n",
    "\t\t   path to the directory containing the R file\n",
    "\terror_string : string\n",
    "\t\t\t\t   original error obtained by running the R script, defaults to\n",
    "\t\t\t\t   \"error\", which will perform the preprocessing\n",
    "\t\"\"\"\n",
    "\t# parse out filename and construct file path\n",
    "\tfilename = r_file.split(\".R\")[0]\n",
    "\tfile_path = path + \"/\" + r_file\n",
    "\t# path to preprocessed file, named with suffix \"_preproc\"\n",
    "\tpreproc_path = path + \"/\" + filename + \"__preproc__\" + \".R\"\n",
    "\t# try all 3 preprocessing methods if there is an error\n",
    "\tif error_string != \"success\":\n",
    "\t\twd_path = preprocess_setwd(r_file, path)\n",
    "\t\tpreprocess_lib(r_file, path, from_preproc=True)\n",
    "\t\tpreprocess_file_paths(r_file, path, wd_path=wd_path, from_preproc=True)\n",
    "\t# else just copy and rename the file\n",
    "\telse:\n",
    "\t\tshutil.copyfile(file_path, preproc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## ESTIMATING MODELS #########################\n",
      "\n",
      "#clean up and options\n",
      "\n",
      "#set working directory, set to YOUR directory\n",
      "\n",
      "#setwd('/Volumes/MONOGAN/polluterPlacement/data')\n",
      "\n",
      "#setwd('/Users/jamie/Desktop/replication/')\n",
      "\n",
      "#setwd('/Users/jamie/Documents/polluterPlacement/data')\n",
      "\n",
      "#load libraries\n",
      "\n",
      "#library(rgeos)\n",
      "\n",
      "#Load data\n",
      "\n",
      "#subset to data under study\n",
      "\n",
      "#census region variable\n",
      "\n",
      "#subset cases and controls separately\n",
      "\n",
      "#How much TRI?\n",
      "\n",
      "####BASE MODELS WITH ROBUSTNESS CHECKS###\n",
      "\n",
      "#Standardized Downwind Distance\n",
      "\n",
      "#GAM model: Non-Standardized Downwind Distance\n",
      "\n",
      "#Standardized Upwind Distance\n",
      "\n",
      "#Standardized Eastern Distance\n",
      "\n",
      "#Standardized Western Distance\n",
      "\n",
      "#pdf('smoothed.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "####REVIEWER-SUGGESTED###\n",
      "\n",
      "#Spatial correlation in residuals\n",
      "\n",
      "#Spatial correlation in raw averages\n",
      "\n",
      "#Spatial correlation in green index\n",
      "\n",
      "#fixed effects, with population density\n",
      "\n",
      "#LaTeX code for output table\n",
      "\n",
      "#convert wind speed to kilomters per hour\n",
      "\n",
      "#regional model\n",
      "\n",
      "#regional effects\n",
      "\n",
      "#pdf('regionConditioning.pdf')\n",
      "\n",
      "#pdf('regionConditioningAlt.pdf')\n",
      "\n",
      "#arrows(x0=region.lower.alt,x1=region.upper,y0=c(1:4),length=0,lty=2,col='red',lwd=2)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#wind speed model\n",
      "\n",
      "#effect of distance by wind\n",
      "\n",
      "#draw graph of effect\n",
      "\n",
      "#pdf('windConditioning.pdf')\n",
      "\n",
      "#lines(x=potential.wind,y=dist.lower,col='red',lty=3)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#threshold model\n",
      "\n",
      "#joint effect after knot point\n",
      "\n",
      "#relevant descriptive statistics\n",
      "\n",
      "#produce output of threshold model for LaTeX\n",
      "\n",
      "#plot spline effect\n",
      "\n",
      "#pdf('splineFunction.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#Green index against proportion of air pollutants\n",
      "\n",
      "#pdf(\"greenAir.pdf\")\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "####PUBLIC V. PRIVATE###\n",
      "\n",
      "#Public\n",
      "\n",
      "#Private\n",
      "\n",
      "####MANUFACTURING MODEL###\n",
      "\n",
      "####MODEL WITH STATE INTERACTIONS####\n",
      "\n",
      "#vis.gam(s.down.inter,view=c(\"longitude\",\"latitude\"),color='gray',plot.type='contour',type='link',cond=list(distance=0),main=\"\", xlab=\"Longitude\", ylab=\"Latitude\")\n",
      "\n",
      "#points(x=full$longitude, y=full$latitude, pch='.')\n",
      "\n",
      "#pdf('forestInteraction.pdf')\n",
      "\n",
      "#arrows(x0=dist.low.80,x1=dist.high.80,y0=c(1:length(dist.coef)),y1=c(1:length(dist.coef)), lwd=3,col='red',angle=90,length=.05,code=3)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('forestInteractionOneTail.pdf')\n",
      "\n",
      "#arrows(x0=dist.low.80,x1=dist.high.80,y0=c(1:length(dist.coef)),y1=c(1:length(dist.coef)), lwd=3,col='red',angle=90,length=.05,code=3)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "####ROBUSTNESS CHECK WITHOUT POWER PLANTS####\n",
      "\n",
      "####ROBUSTNESS CHECK WITH POWER PLANTS ONLY####\n",
      "\n",
      "####MAPS OF SELECTED STATES####\n",
      "\n",
      "#pdf('california.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('california0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('indiana.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('indiana0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('michigan.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('michigan0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('iowa.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('iowa0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('texas.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('texas0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('georgia.pdf')\n",
      "\n",
      "#jpeg('georgiaPollution.jpg',width=870,height=300,quality=100)\n",
      "\n",
      "#jpeg('georgiaPollution.jpg',width=300,height=300)\n",
      "\n",
      "#plot(ga.map,type='n',xlab=\"\",ylab=\"\",axes=F,asp=1)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('georgia0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('minnesota.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "#pdf('minnesota0.pdf')\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "####TOXICITY ANALYSIS####\n",
      "\n",
      "#create subsets\n",
      "\n",
      "#GAM models\n",
      "\n",
      "##FOREST PLOT##\n",
      "\n",
      "#pdf('forest.pdf')\n",
      "\n",
      "#arrows(x0=dist.low.80,x1=dist.high.80,y0=c(1:length(dist.coef)),y1=c(1:length(dist.coef)), lwd=3,col='red',angle=90,length=.05,code=3)\n",
      "\n",
      "#dev.off()\n",
      "\n",
      "####NO CONTROL GROUP: INHOMOGENOUS POISSON PROCESS###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"r_datasets_test/doi--10.7910-DVN-26905/lower48control.R\",\n",
    "          \"r\") as handle:\n",
    "    for line in handle.readlines():\n",
    "        if re.match(\"^#\", line):\n",
    "            print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"odyssey_job_schedule.txt\", \"r\") as infile:\n",
    "    with open(\"odyssey_job_numbers.txt\", 'w') as outfile:\n",
    "        for line in infile.readlines():\n",
    "            outfile.write((line.split(\" \")[-1]).strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_err_files = []\n",
    "with open(\"odyssey_job_numbers.txt\", 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        job_err_files.append('provR' + line.strip() + '.err')\n",
    "\n",
    "for job_err_file in job_err_files:\n",
    "    with open(job_err_file, 'r') as infile:\n",
    "        reached_time_limit = False\n",
    "        for line in infile.readlines():\n",
    "            if \"DUE TO TIME LIMIT\" in line:\n",
    "                reached_time_limit = True\n",
    "    if reached_time_limit:\n",
    "        with open(\"all.err\", \"a+\") as outfile:\n",
    "            with open(job_err_file, 'r') as infile:\n",
    "                map(outfile.write, infile.readlines())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of dataset directories, ignoring macOS directory metadata file (if present)\n",
    "doi_directs = [doi for doi in os.listdir(\"rdata_odyc\") if doi != '.DS_Store']\n",
    "\n",
    "dois_with_subdirs = []\n",
    "\n",
    "# iterate through directories and concatenate run logs\n",
    "for my_doi in doi_directs:\n",
    "    subdirs = [content for content in os.listdir(\"rdata_odyc/\" + my_doi) \\\n",
    "               if content != \"prov_data\"\\\n",
    "               and os.path.isdir('/'.join([\"rdata_odyc\", my_doi, content]))]\n",
    "    if subdirs:\n",
    "        dois_with_subdirs.append(my_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doi_directs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(doi_directs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois_with_subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doi--10.7910-DVN-I2CZQY', 'doi--10.7910-DVN-CKCTJS']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dois_with_subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_FigureS1_SEI_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Figure23_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_FigureS1_SEI.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/KGSS_Daughter_Data Setup_Analysis.do',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Data Setup.do',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Analysis_Bart_FigureS2_TableS8.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Bart_Data Setup_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/daughter_analytic.dta',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/minqa',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Figure23.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/abind',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Analysis_Bart_Figure4_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/lme4',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Analysis.do',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/prov_data',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Analysis_Bart_FigureS2_TableS8_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_FigureS3_KGSS_preproc0.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/nloptr',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/kgss_analytic.dta',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/RcppEigen',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Analysis_Bart_Figure4.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/arm',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_FigureS3_KGSS.R',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/coda',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/ESS_Occupation_SEIscores.do',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Rcpp',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/README_daughter.txt',\n",
       " 'rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_Bart_Data Setup.R']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('rdata_odyc/doi--10.7910-DVN-CKCTJS/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rdata_odyc/doi--10.7910-DVN-CKCTJS/Daughter_FigureS1_SEI_preproc0.R', 'r') as my_file:\n",
    "    my_file_list = []\n",
    "    map(my_file_list.append, my_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7f53cb88d017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^\\s*source\\s*\\((?:.*?file\\s*=\\s*|\\s*)\\\"([^\\\"]+.R)\\\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"source(\\\"rdatatracker.c\\\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "re.match('^\\s*source\\s*\\((?:.*?file\\s*=\\s*|\\s*)\\\"([^\\\"]+.R)\\\"', \"source(\\\"rdatatracker.c\\\")\").group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
